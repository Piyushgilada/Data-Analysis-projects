{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/4G/QFdik87LGO69kfzoe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Objective :- Data extraction and NLP\n"],"metadata":{"id":"6ZplZxVMCEtr"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FskfTXAX8u6K","executionInfo":{"status":"ok","timestamp":1702735865725,"user_tz":-330,"elapsed":24256,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}},"outputId":"a1705a0c-cc22-4ebe-9cbc-a95668b022ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd '/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1'"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import os\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import re"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9s5qmYC85qB","executionInfo":{"status":"ok","timestamp":1702735920216,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}},"outputId":"163da262-d384-4dfc-ac20-12dd924d906c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["**Data Extraction**"],"metadata":{"id":"P6F0BaNmCbZc"}},{"cell_type":"code","source":["# Read the url file\n","df = pd.read_excel('/content/Input.xlsx')\n","\n","# loop for each row in the df\n","for index, row in df.iterrows():\n","  url = row['URL']\n","  url_id = row['URL_ID']\n","\n","  # make a request\n","  header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n","  try:\n","    response = requests.get(url,headers=header)\n","  except:\n","    print(\"can't get response of {}\".format(url_id))\n","\n","  # create object of beautifulsoup\n","  try:\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","  except:\n","    print(\"can't get page of {}\".format(url_id))\n","\n","  # find title\n","  try:\n","    title = soup.find('h1').get_text()\n","  except:\n","    print(\"can't get title of {}\".format(url_id))\n","    continue\n","\n","  # find text\n","  article = \"\"\n","  try:\n","    for p in soup.find_all('p'):\n","      article += p.get_text()\n","  except:\n","    print(\"can't get text of {}\".format(url_id))\n","\n","  # write title and text in file\n","  file_name = '/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1/TitleText/' + str(url_id) + '.txt'\n","  with open(file_name, 'w') as file:\n","    file.write(title + '\\n' + article)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qaE0A30-Hgm","executionInfo":{"status":"ok","timestamp":1702736019014,"user_tz":-330,"elapsed":58940,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}},"outputId":"c210f80f-dbd1-4919-bea6-7f9d6a11d303"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["can't get title of blackassign0036\n","can't get title of blackassign0049\n"]}]},{"cell_type":"code","source":["# Directories\n","text_dir = \"/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1/TitleText\"\n","stopwords_dir = \"/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1/StopWords\"\n","sentment_dir = \"/gdrive/MyDrive/project/Data_Extraction_and_NLP/TestAssignment1/MasterDictionary\"\n","\n","# load stop words from stopwords and store into set variable\n","stop_words = set()\n","for files in os.listdir(stopwords_dir):\n","  with open(os.path.join(stopwords_dir,files),'r',encoding='ISO-8859-1') as f:\n","    stop_words.update(set(f.read().splitlines()))\n","\n","# load text files from the directory and store into list\n","docs = []\n","for text_file in os.listdir(text_dir):\n","  with open(os.path.join(text_dir,text_file),'r') as f:\n","    text = f.read()\n","\n","# tokenize the text file\n","    words = word_tokenize(text)\n","\n","# remove the stop words from the tokens\n","    filtered_text = [word for word in words if word.lower() not in stop_words]\n","\n","# add filtered tokens into a list\n","    docs.append(filtered_text)\n","\n","# store positive, Negative words from the directory\n","pos=set()\n","neg=set()\n","\n","for files in os.listdir(sentment_dir):\n","  if files =='positive-words.txt':\n","    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n","      pos.update(f.read().splitlines())\n","  else:\n","    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n","      neg.update(f.read().splitlines())\n","\n","# now collect the positive & negative words file\n","# calculate the scores from the positive & negative words\n","positive_words = []\n","Negative_words =[]\n","positive_score = []\n","negative_score = []\n","polarity_score = []\n","subjectivity_score = []\n","\n","# Iterate through the list of docs\n","for i in range(len(docs)):\n","  positive_words.append([word for word in docs[i] if word.lower() in pos])\n","  Negative_words.append([word for word in docs[i] if word.lower() in neg])\n","  positive_score.append(len(positive_words[i]))\n","  negative_score.append(len(Negative_words[i]))\n","  polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n","  subjectivity_score.append((positive_score[i] + negative_score[i]) / ((len(docs[i])) + 0.000001))"],"metadata":{"id":"Rg-ALaoF-IBm","executionInfo":{"status":"ok","timestamp":1702736087113,"user_tz":-330,"elapsed":5391,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**Data Analysis**"],"metadata":{"id":"eeYMSraeDf5U"}},{"cell_type":"code","source":["# Average SentenceLength = the number of words / the number of sentences\n","# Percentage of Complexwords = the number of complexwords / the number of words\n","# FogIndex = 0.4 * (Average SentenceLength + Percentage of Complexwords)\n","\n","avg_sentence_length = []\n","Percentage_of_Complex_words  =  []\n","Fog_Index = []\n","complex_word_count =  []\n","avg_syllable_word_count =[]\n","\n","stopwords = set(stopwords.words('english'))\n","def measure(file):\n","  with open(os.path.join(text_dir, file),'r') as f:\n","    text = f.read()\n","\n","# remove punctuations\n","    text = re.sub(r'[^\\w\\s.]','',text)\n","\n","# split the text file into sentences\n","    sentences = text.split('.')\n","\n","# number of sentences in file\n","    num_sentences = len(sentences)\n","\n","# total words in file\n","    words = [word  for word in text.split() if word.lower() not in stopwords ]\n","    num_words = len(words)\n","\n","# complex words having syllable count is >2\n","# Complex words are words in text that contains more than two syllables.\n","\n","    complex_words = []\n","    for word in words:\n","      vowels = 'aeiou'\n","      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n","      if syllable_count_word > 2:\n","        complex_words.append(word)\n","\n","# Syllable Count Per Word\n","# We count the number of Syllables in each word of the text by counting the vowels present in each word.\n","#  We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable.\n","\n","    syllable_count = 0\n","    syllable_words =[]\n","    for word in words:\n","      if word.endswith('es'):\n","        word = word[:-2]\n","      elif word.endswith('ed'):\n","        word = word[:-2]\n","      vowels = 'aeiou'\n","      syllable_count_word = sum( 1 for letter in word if letter.lower() in vowels)\n","      if syllable_count_word >= 1:\n","        syllable_words.append(word)\n","        syllable_count += syllable_count_word\n","\n","\n","    avg_sentence_len = num_words / num_sentences\n","    avg_syllable_word_count = syllable_count / len(syllable_words)\n","    Percent_Complex_words  =  len(complex_words) / num_words\n","    Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n","\n","    return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words),avg_syllable_word_count\n","\n","# iterate through each file or doc\n","for file in os.listdir(text_dir):\n","  x,y,z,a,b = measure(file)\n","  avg_sentence_length.append(x)\n","  Percentage_of_Complex_words.append(y)\n","  Fog_Index.append(z)\n","  complex_word_count.append(a)\n","  avg_syllable_word_count.append(b)"],"metadata":{"id":"EdjCommX-q9u","executionInfo":{"status":"ok","timestamp":1702736103478,"user_tz":-330,"elapsed":653,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Word Count and Average Word Length Sum of the total number of characters in each word/Total number of words\n","# We count the total cleaned words present in the text by\n","# removing the stop words (using stopwords class of nltk package).\n","# removing any punctuations like ? ! , . from the word before counting.\n","\n","def cleaned_words(file):\n","  with open(os.path.join(text_dir,file), 'r') as f:\n","    text = f.read()\n","    text = re.sub(r'[^\\w\\s]', '' , text)\n","    words = [word  for word in text.split() if word.lower() not in stopwords]\n","    length = sum(len(word) for word in words)\n","    average_word_length = length / len(words)\n","  return len(words),average_word_length\n","\n","word_count = []\n","average_word_length = []\n","for file in os.listdir(text_dir):\n","  x, y = cleaned_words(file)\n","  word_count.append(x)\n","  average_word_length.append(y)\n","\n","\n","# To calculate Personal Pronouns mentioned in the text, we use regex to find\n","# the counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken\n","#  so that the country name US is not included in the list.\n","def count_personal_pronouns(file):\n","  with open(os.path.join(text_dir,file), 'r') as f:\n","    text = f.read()\n","    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n","    count = 0\n","    for pronoun in personal_pronouns:\n","      count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text)) # \\b is used to match word boundaries\n","  return count\n","\n","pp_count = []\n","for file in os.listdir(text_dir):\n","  x = count_personal_pronouns(file)\n","  pp_count.append(x)"],"metadata":{"id":"pCTRudDh-vrA","executionInfo":{"status":"ok","timestamp":1702736116474,"user_tz":-330,"elapsed":1287,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**Variables**"],"metadata":{"id":"CMeFSIJCC1N0"}},{"cell_type":"markdown","source":["**Output Data**"],"metadata":{"id":"Bmy3tyT1C9pV"}},{"cell_type":"code","source":["output_df = pd.read_excel('/content/Output Data Structure.xlsx')\n","\n","# URL_ID 44 ,57, 144 does not exists i,e. page does not exist, throughs 404 error\n","# so we are going to drop these rows from the table\n","output_df.drop([44-37,57-37,144-37], axis = 0, inplace=True)\n","\n","# These are the required parameters\n","variables = [positive_score,\n","            negative_score,\n","            polarity_score,\n","            subjectivity_score,\n","            avg_sentence_length,\n","            Percentage_of_Complex_words,\n","            Fog_Index,\n","            avg_sentence_length,\n","            complex_word_count,\n","            word_count,\n","            avg_syllable_word_count,\n","            pp_count,\n","            average_word_length]\n","\n","# # write the values to the dataframe\n","for i, var in enumerate(variables):\n","  var = output_df.iloc[:,0:i+2]\n","\n","#now save the dataframe to the disk\n","output_df.to_csv('/content/Output_Data.csv')"],"metadata":{"id":"f-LsnQYk-zMY","executionInfo":{"status":"ok","timestamp":1702736177655,"user_tz":-330,"elapsed":808,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df1=pd.read_csv('/content/Output_Data.csv')"],"metadata":{"id":"al0InQh_-7Hy","executionInfo":{"status":"ok","timestamp":1702737255702,"user_tz":-330,"elapsed":4244,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["df1.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"id":"aeHVQCKeDH-c","executionInfo":{"status":"ok","timestamp":1702737291003,"user_tz":-330,"elapsed":832,"user":{"displayName":"Piyush Gilada","userId":"07325341389724426869"}},"outputId":"649d7f53-d961-4548-abe2-b17b24fc5daa"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  URL_ID                                                URL  \\\n","0           0      37  https://insights.blackcoffer.com/ai-in-healthc...   \n","1           1      38  https://insights.blackcoffer.com/what-if-the-c...   \n","2           2      39  https://insights.blackcoffer.com/what-jobs-wil...   \n","3           3      40  https://insights.blackcoffer.com/will-machine-...   \n","4           4      41  https://insights.blackcoffer.com/will-ai-repla...   \n","5           5      42  https://insights.blackcoffer.com/man-and-machi...   \n","6           6      43  https://insights.blackcoffer.com/in-future-or-...   \n","7           8      45  https://insights.blackcoffer.com/how-machine-l...   \n","8           9      46  https://insights.blackcoffer.com/deep-learning...   \n","9          10      47  https://insights.blackcoffer.com/how-to-protec...   \n","\n","   POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n","0             NaN             NaN             NaN                 NaN   \n","1             NaN             NaN             NaN                 NaN   \n","2             NaN             NaN             NaN                 NaN   \n","3             NaN             NaN             NaN                 NaN   \n","4             NaN             NaN             NaN                 NaN   \n","5             NaN             NaN             NaN                 NaN   \n","6             NaN             NaN             NaN                 NaN   \n","7             NaN             NaN             NaN                 NaN   \n","8             NaN             NaN             NaN                 NaN   \n","9             NaN             NaN             NaN                 NaN   \n","\n","   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n","0                  NaN                          NaN        NaN   \n","1                  NaN                          NaN        NaN   \n","2                  NaN                          NaN        NaN   \n","3                  NaN                          NaN        NaN   \n","4                  NaN                          NaN        NaN   \n","5                  NaN                          NaN        NaN   \n","6                  NaN                          NaN        NaN   \n","7                  NaN                          NaN        NaN   \n","8                  NaN                          NaN        NaN   \n","9                  NaN                          NaN        NaN   \n","\n","   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n","0                               NaN                 NaN         NaN   \n","1                               NaN                 NaN         NaN   \n","2                               NaN                 NaN         NaN   \n","3                               NaN                 NaN         NaN   \n","4                               NaN                 NaN         NaN   \n","5                               NaN                 NaN         NaN   \n","6                               NaN                 NaN         NaN   \n","7                               NaN                 NaN         NaN   \n","8                               NaN                 NaN         NaN   \n","9                               NaN                 NaN         NaN   \n","\n","   SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n","0                NaN                NaN              NaN  \n","1                NaN                NaN              NaN  \n","2                NaN                NaN              NaN  \n","3                NaN                NaN              NaN  \n","4                NaN                NaN              NaN  \n","5                NaN                NaN              NaN  \n","6                NaN                NaN              NaN  \n","7                NaN                NaN              NaN  \n","8                NaN                NaN              NaN  \n","9                NaN                NaN              NaN  "],"text/html":["\n","  <div id=\"df-b6160ea0-f1dd-4851-82e5-4bac9fe94584\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>URL_ID</th>\n","      <th>URL</th>\n","      <th>POSITIVE SCORE</th>\n","      <th>NEGATIVE SCORE</th>\n","      <th>POLARITY SCORE</th>\n","      <th>SUBJECTIVITY SCORE</th>\n","      <th>AVG SENTENCE LENGTH</th>\n","      <th>PERCENTAGE OF COMPLEX WORDS</th>\n","      <th>FOG INDEX</th>\n","      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n","      <th>COMPLEX WORD COUNT</th>\n","      <th>WORD COUNT</th>\n","      <th>SYLLABLE PER WORD</th>\n","      <th>PERSONAL PRONOUNS</th>\n","      <th>AVG WORD LENGTH</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>37</td>\n","      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>38</td>\n","      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>39</td>\n","      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>40</td>\n","      <td>https://insights.blackcoffer.com/will-machine-...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>41</td>\n","      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>42</td>\n","      <td>https://insights.blackcoffer.com/man-and-machi...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>43</td>\n","      <td>https://insights.blackcoffer.com/in-future-or-...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>45</td>\n","      <td>https://insights.blackcoffer.com/how-machine-l...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>46</td>\n","      <td>https://insights.blackcoffer.com/deep-learning...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>47</td>\n","      <td>https://insights.blackcoffer.com/how-to-protec...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6160ea0-f1dd-4851-82e5-4bac9fe94584')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b6160ea0-f1dd-4851-82e5-4bac9fe94584 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b6160ea0-f1dd-4851-82e5-4bac9fe94584');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-1602a62f-7146-4701-ac41-2924278a4b8e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1602a62f-7146-4701-ac41-2924278a4b8e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-1602a62f-7146-4701-ac41-2924278a4b8e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"4P3__QdmDKKb"},"execution_count":null,"outputs":[]}]}